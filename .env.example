# AI Trade Execution Analyzer - Environment Variables

# LLM Provider Configuration
# --------------------------
# Anthropic API Key (required for Claude)
ANTHROPIC_API_KEY=sk-ant-api03-xxx

# OpenAI API Key (optional, for GPT-4)
OPENAI_API_KEY=sk-xxx

# Default LLM provider: "anthropic" or "openai"
LLM_PROVIDER=anthropic

# Default model to use
LLM_MODEL=claude-3-5-sonnet-20241022

# Maximum tokens in response
LLM_MAX_TOKENS=4096

# Temperature for sampling (0.0 = deterministic)
LLM_TEMPERATURE=0.0

# Request timeout in seconds
LLM_TIMEOUT=60.0

# Retry configuration
LLM_MAX_RETRIES=3
LLM_RETRY_BASE_DELAY=1.0
LLM_RETRY_MAX_DELAY=30.0

# Langfuse Observability
# ----------------------
# Get these from https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=pk-lf-xxx
LANGFUSE_SECRET_KEY=sk-lf-xxx

# Enable/disable Langfuse tracing
LANGFUSE_ENABLED=true

# Langfuse host (optional, for self-hosted)
# LANGFUSE_HOST=https://cloud.langfuse.com

# Enable Langfuse debug mode
LANGFUSE_DEBUG=false

# Application Settings
# --------------------
# Application version (for release tracking)
APP_VERSION=0.1.0

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Enable debug mode (verbose logging)
DEBUG=false
